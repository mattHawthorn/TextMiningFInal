{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks to decide on the best document vector representation for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the vectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/home/matt/Git/TextMiningFinal/data/vectors/'\n",
    "with open(os.path.join(datapath,'20_newsgroups_simple.p'),'rb') as docfile:\n",
    "    docs = pickle.load(docfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add two integer-keyed dicts as if they were vectors\n",
    "def add_dicts(*vecs):\n",
    "    v1 = vecs[0]\n",
    "    v2 = vecs[1]\n",
    "    keys = set(v1).union(v2) if len(v1)<len(v2) else set(v2).union(v1)\n",
    "    result = {}\n",
    "    for key in keys:\n",
    "        result[key] = v1.get(key,0) + v2.get(key,0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reduce the indices of the docs to range(0,total_distinct_indices_in_docs): makes for smaller np arrays\n",
    "def compress_indices(docs):\n",
    "    # collect all the indices that actually appear\n",
    "    indices = {}\n",
    "    newdocs = []\n",
    "    i = 0\n",
    "    for doc in docs:\n",
    "        newdoc = {}\n",
    "        for key in doc:\n",
    "            index = indices.get(key,i)\n",
    "            newdoc[index] = doc[key]\n",
    "            if index==i:\n",
    "                indices[key] = i\n",
    "                i+=1\n",
    "        newdocs.append(newdoc)\n",
    "    return newdocs,len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduce the indices of the docs to range(0,total_distinct_indices_in_docs): makes for smaller np arrays\n",
    "def compress_indices2(docs):\n",
    "    # collect all the indices that actually appear\n",
    "    indices = set()\n",
    "    docs = list(docs)\n",
    "    for doc in docs:\n",
    "        for key in doc:\n",
    "            indices.add(key)\n",
    "    # now connect them to new indices\n",
    "    mapping = dict(zip(indices,range(len(indices))))\n",
    "    newdocs = []\n",
    "    for doc in docs:\n",
    "        newdoc = {}\n",
    "        for key in doc:\n",
    "            newdoc[mapping[key]] = doc[key]\n",
    "        newdocs.append(newdoc)\n",
    "    # return both the new docs and the total number of indices, for properly shaping numpy arrays later\n",
    "    return newdocs, len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert sparse dict representation to a dense numpy array with the specified size\n",
    "def dict_to_np(d,length):\n",
    "    v = np.zeros((1,length),dtype='float')\n",
    "    for k,c in d.items():\n",
    "        v[0,k] = c\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests on some dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 4, 5}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1={0:1,1:2,2:3}\n",
    "d2={2:3,4:5,5:6}\n",
    "set(d1).union(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 2, 2: 6, 4: 5, 5: 6}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_dicts(d1,d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  0.  0.  0.]]\n",
      "[[ 1.  2.  6.  0.  5.  6.]]\n"
     ]
    }
   ],
   "source": [
    "# note the zeros being filled in to non-indexed positions\n",
    "print(dict_to_np(d1,6))\n",
    "print(dict_to_np(add_dicts(d1,d2),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{0: 1, 1: 2, 2: 3}, {2: 3, 3: 5, 4: 6}], 5)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and note here that the indices 4 and 5 get decremented, since the index 3 is never used\n",
    "compress_indices([d1,d2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{0: 1, 1: 2, 2: 3}, {2: 3, 3: 5, 4: 6}], 5)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and note here that the indices 4 and 5 get decremented, since the index 3 is never used\n",
    "compress_indices2([d1,d2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 235 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit compress_indices(map(itemgetter(2),docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 241 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit compress_indices2(map(itemgetter(2),docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests on samples of our real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reduce the indices and set the vocab size\n",
    "vdocs, V = compress_indices(map(itemgetter(2),docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7662"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V\n",
    "# 7662, the right number according to the notebook that vectorized the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_time(func,*args,iterations=10):\n",
    "    times = []\n",
    "    for i in range(iterations):\n",
    "        start = time.time()\n",
    "        func(*args)\n",
    "        end = time.time()\n",
    "        times.append(end-start)\n",
    "    return min(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "iterations = 30\n",
    "results = DataFrame(index = range(sample_size),columns= ['np','dict','csr','coo','dok'])\n",
    "\n",
    "for i in results.index:\n",
    "    # choose two random docs\n",
    "    indices = np.random.randint(0,len(vdocs),2)\n",
    "\n",
    "    # get their vectors as dicts\n",
    "    d1 = vdocs[indices[0]]\n",
    "    d2 = vdocs[indices[1]]\n",
    "\n",
    "    # translate them to numpy arrays\n",
    "    v1 = dict_to_np(d1,V)\n",
    "    v2 = dict_to_np(d2,V)\n",
    "    \n",
    "    # translate to all the scipy sparse types\n",
    "    v1_dok = sparse.dok_matrix(v1)\n",
    "    v2_dok = sparse.dok_matrix(v2)\n",
    "\n",
    "    v1_coo = sparse.coo_matrix(v1)\n",
    "    v2_coo = sparse.coo_matrix(v2)\n",
    "\n",
    "    v1_csr = sparse.csr_matrix(v1)\n",
    "    v2_csr = sparse.csr_matrix(v2)\n",
    "    \n",
    "    # apply all the binary functions to them\n",
    "    ops = [np.add,add_dicts,np.add,np.add,np.add]\n",
    "    args = [(v1,v2),(d1,d2),(v1_csr,v2_csr),(v1_coo,v2_coo),(v1_dok,v2_dok)]\n",
    "    times = [get_best_time(ops[i],*args[i],iterations=iterations) for i in range(len(ops))]\n",
    "    \n",
    "    # and store the results\n",
    "    results.loc[i,['np','dict','csr','coo','dok']] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np      0.000004\n",
       "dict    0.000071\n",
       "csr     0.000121\n",
       "coo     0.000250\n",
       "dok     0.002518\n",
       "dtype: float64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy dense is the clear winner!\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results on log2 scale: every increase of 1 in y means a doubling of execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c6b0bdf28>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAJPCAYAAABVSyFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c6f153b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "results.applymap(np.log2).plot.box(grid=True)#ylim=(0,.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: plain old numpy beats everything else with flying colors (and note that our plain old dict implementation beats all the sparse implementations at least 3-fold, albeit with higher variance).  Since the maximum dimension of our datasets is ~10000 this shouldn't be a problem.  Moreover, this will allow us to use a common implementation of clustering for both topic vectors and term vectors, since numpy makes the most sense in the topic vector case from the start, with dimensionality only in the hundreds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the memory size of the whole corpus in different formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of corpus (Mb) in numpy format:\n",
      "662 Mb\n",
      "Size of corpus in dict format:\n",
      "35 Mb\n",
      "Size of corpus (Mb) in sparse csr format:\n",
      "0.604233 Mb\n",
      "Size of corpus (Mb) in sparse coo format:\n",
      "0.604233 Mb\n",
      "Size of corpus (Mb) in sparse dok format:\n",
      "47.694031 Mb\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of corpus (Mb) in numpy format:\")\n",
    "print(\"%d Mb\" %(sum([sys.getsizeof(dict_to_np(doc,V)) for doc in vdocs])/(1024**2)))\n",
    "print(\"Size of corpus in dict format:\")\n",
    "print(\"%d Mb\" %(sum([sys.getsizeof(doc) for doc in vdocs])/(1024**2)))\n",
    "print(\"Size of corpus (Mb) in sparse csr format:\")\n",
    "print(\"%f Mb\" %(sum([sys.getsizeof(sparse.csr_matrix(dict_to_np(doc,V))) for doc in vdocs])/(1024**2)))\n",
    "print(\"Size of corpus (Mb) in sparse coo format:\")\n",
    "print(\"%f Mb\" %(sum([sys.getsizeof(sparse.coo_matrix(dict_to_np(doc,V))) for doc in vdocs])/(1024**2)))\n",
    "print(\"Size of corpus (Mb) in sparse dok format:\")\n",
    "print(\"%f Mb\" %(sum([sys.getsizeof(sparse.dok_matrix(dict_to_np(doc,V))) for doc in vdocs])/(1024**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obviously there's a huge blow-up in memory usage from sparse to dict to numpy, 1000-fold overall, but for our dataset it's simply not an issue; we have 662 Mb to spare.\n",
    "### (note that we're beating the scipy dok format in memory usage and destroying it completely in execution time with just a dict implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
